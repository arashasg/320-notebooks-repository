{"cells":[{"metadata":{"_uuid":"3ba4bdf531da416da0f2ffe404f915ede4d2ad2a","_cell_guid":"219e00c2-8610-425e-af91-674aa95c5bad"},"cell_type":"markdown","source":"# Content\n1. Introduction\n2. Dataset description\n3. Double Exponential Smoothing algorithm theory\n4. Double Exponential Smoothing implementation\n5. Forecast evaluation\n6. Conclusion\n***\n"},{"metadata":{"_uuid":"7f95795849b58b392ec73780f11a0a6e6b053a92","_cell_guid":"44fa0822-6999-4383-81eb-3961a1855499"},"cell_type":"markdown","source":"## 1. Introduction\nA smoothing method reduces the effects of random variations that the deterministic components of a time series can have. With the help of smoothing methods we can also forecast new observations for a given time series. The algorithms that use smooting methods can forecast data for time series that have got or haven't got a trend. If an algorithm using smooting methods is designed to forecast an observation on a time series that has a trend, we should NOT use that algorithm to forecast a time series that does not have a trend and vice versa. [Here](https://www.kaggle.com/andreicosma/introduction-in-time-series-moving-average) you can find a beginner friendly tutorial to introduce you into time series and smoothing methods.\n***"},{"metadata":{"_uuid":"b76c8a03a405ef4fec327ebb99fe79173d93c195","_cell_guid":"26eefa74-1b83-4632-9d0e-57037ac11280"},"cell_type":"markdown","source":"## 2. Dataset description\nOur time series observations that will be used in this example are the numbers of shampoo sales over a period of 3 years. We can see below how our time series looks like:"},{"metadata":{"_uuid":"fad48bebf8f31c16c516f5db13f989e3e0e9bdf7","_cell_guid":"207d078a-ead4-463d-b9b8-34b0d9f8a96c","collapsed":true,"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ncsv_dataset = pd.read_csv(\"../input/sales_of_shampoo_over_a_three_ye.csv\")\ncsv_dataset.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c949ecf2367611904c6ed6cb9ebe1f47b5bf0409","_cell_guid":"a0c3ae3a-0729-4b56-9bfc-708541a7a81a","collapsed":true},"cell_type":"markdown","source":"As we can see, the data HAS got an ascending trend and it's composed of 36 observations. In this example we will forecast the next observation.\n***"},{"metadata":{"_uuid":"dd1d038892c61b660ec9bac77828b2177564b2b7","_cell_guid":"9bb48040-9023-4693-bafa-d5b9d963a3af"},"cell_type":"markdown","source":"## 3. Double Exponential Smoothing algorithm theory\nThis algorithm helps us to forecast new observations based on a time series. This algorithm uses smoothing methods. The ,,Double Exponential Smoothing\" algorithm is used only on time series that HAVE a trend. On time series that have a trend  the [,,Exponential Smoothing''](https://www.kaggle.com/andreicosma/time-series-exponential-smoothing) algorithm does not perform very well. [Here](https://www.kaggle.com/andreicosma/time-series-exponential-smoothing) you can learn about the exponential smoothing algorithm. This problem was solved by adding a second smoothing constant: ,,gamma\". The mathematical model for this algorithm is:\n![](https://preview.ibb.co/idX49x/des.png)"},{"metadata":{"_uuid":"10bddd2073fa134e36cfdcb81ac51f196fa94b46","_cell_guid":"68a3085d-a645-4f01-9443-6c2b20b0e6f7"},"cell_type":"markdown","source":"where ,,alpha\" and ,,gamma\" are the smoothing constants and they can take values between 0 and 1, ,,P_t'' is the forecast at time ,,t'', X_t is the time series observation at time ,,t'', b_t is the trend value at time ,,t''. In this case we have to solve two problems:\n1. Choosing the values of P_1 and b_1;\n2. Choosing the values of ,,alpha\" and ,,gamma\".\n\nFor the first problem we can choose P_1 to be equal to the first observation and for b_1 we have two common options:\n1. we can choose it to be the second observation minus the first (b_1 = x_2 - x_1);\n2. we can choose it to be the last observation minus the first, all divided by the total number of observations minus 1 ( b_1 = (x_n - x_1)/(n - 1)).\n\nTo solve the second problem we can use the ,,incremental method'': We set the value of alpha (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9) and gamma (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), then we calculate the coresponding [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) for each value that alpha and gamma take. After that, we choose the alpha and gamma with the minimum MSE.\n\nAfter we got the optimal alpha and gamma and we have calibrated the trend with the formula presented above we can forecast the next ,,m'' periods of time using the following formula:\n![](https://image.ibb.co/hvNJKx/dess.png)\n\n***"},{"metadata":{"_uuid":"44ba7a8b7eb6473f6aa791788b4f667546ece0fe","_cell_guid":"6ee2e71a-4678-4f57-bafc-3db1ab19e251"},"cell_type":"markdown","source":"\n## 4. Double Exponential Smoothing implementation\nThe following section will propose an algorithm for finding the best alpha and gamma. The algorithm will start at alpha = 0.1 and gamma = 01 and will go up to gamma = 0.9 then incrementing the alpha to alpha = 0.9. For each alpha and beta, the algorithm will forecast the already known observations along with the correspondent MSE followed by choosing the alpha and beta with the minimum MSE value.\n"},{"metadata":{"_uuid":"7d07a462b9a502f33f99d0fb3bce55fc6fcc8d67","_cell_guid":"fb6be87a-060e-488e-becb-af394556c257","collapsed":true,"trusted":false},"cell_type":"code","source":"optimal_alpha = None\noptimal_gamma = None\nbest_mse = None\ndb = csv_dataset.iloc[:, :].values.astype('float32')\nmean_results_for_all_possible_alpha_gamma_values = np.zeros((9, 9))\nfor gamma in range(0, 9):\n    for alpha in range(0, 9):\n        pt = db[0][0]\n        bt = db[1][0] - db[0][0]\n        mean_for_alpha_gamma = np.zeros(len(db))\n        mean_for_alpha_gamma[0] = np.power(db[0][0] - pt, 2)\n        for i in range(1, len(db)):\n            temp_pt = ((alpha + 1) * 0.1) * db[i][0] + (1 - ((alpha + 1) * 0.1)) * (pt + bt)\n            bt = ((gamma + 1) * 0.1) * (temp_pt - pt) + (1 - ((gamma + 1) * 0.1)) * bt\n            pt = temp_pt\n            mean_for_alpha_gamma[i] = np.power(db[i][0] - pt, 2)\n        mean_results_for_all_possible_alpha_gamma_values[gamma][alpha] = np.mean(mean_for_alpha_gamma)\n        optimal_gamma, optimal_alpha = np.unravel_index(\n            np.argmin(mean_results_for_all_possible_alpha_gamma_values),\n            np.shape(mean_results_for_all_possible_alpha_gamma_values))\noptimal_alpha = (optimal_alpha + 1) * 0.1\noptimal_gamma = (optimal_gamma + 1) * 0.1\nbest_mse = np.min(mean_results_for_all_possible_alpha_gamma_values)\nprint(\"Best MSE = %s\" % best_mse)\nprint(\"Optimal alpha = %s\" % optimal_alpha)\nprint(\"Optimal gamma = %s\" % optimal_gamma)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3005579f81990b20ee7582b34eccb801bf0fc807","_cell_guid":"59a61773-4c19-4138-9da3-8f3e5e112f9b"},"cell_type":"markdown","source":"After the optimal ,,alpha'' and ,,gamma\" have been found, we can calibrate the trend as following:"},{"metadata":{"_uuid":"b0205f12cd2e5143123c55daaa5cdbeb7c34b88d","_cell_guid":"2a2e6548-c9ee-4ac4-b1a9-c7f873985930","collapsed":true,"trusted":false},"cell_type":"code","source":"pt = db[0][0]\nbt = db[1][0] - db[0][0]\nfor i in range(1, len(db)):\n    temp_pt = optimal_alpha * db[i][0] + (1 - optimal_alpha) * (pt + bt)\n    bt = optimal_gamma * (temp_pt - pt) + (1 - optimal_gamma) * bt\n    pt = temp_pt\nprint(\"P_t = %s\" % pt)\nprint(\"b_t = %s\" % bt )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69f6b4cee78b66e806275bf7041e0c84f9c16077","_cell_guid":"bce38407-d2e4-4250-87a9-23d496a6bad7"},"cell_type":"markdown","source":"Now we can forecast the next ,,m'' periods of time using the formula from section 3 like this:"},{"metadata":{"_uuid":"f56acc115ba20522aa2fade903792e2d4ef7ab8b","_cell_guid":"b25c15d2-ed29-4b07-bce1-4211de44203b","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\"Next observation = %s\" % (pt + (1 * bt)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7856aeccb72bf8306cd38849de586f1c31c0b7e","_cell_guid":"82931c13-1a21-466a-8981-3760251231d7"},"cell_type":"markdown","source":"***\n## 5. Forecast evaluation\nIn this section we will compare the forecast data with the real data for the optimal ,,alpha'' and ,,gamma''."},{"metadata":{"_uuid":"d9cc5dcace64d229e8d6948f0ef5a937c5e3b920","_cell_guid":"a5c6e884-1bca-43d6-9d1d-1e330fc09b37","collapsed":true,"trusted":false},"cell_type":"code","source":"forecast = np.zeros(len(db) + 1)\npt = db[0][0]\nbt = db[1][0] - db[0][0]\nforecast[0] = pt\nfor i in range(1, len(db)):\n    temp_pt = optimal_alpha * db[i][0] + (1 - optimal_alpha) * (pt + bt)\n    bt = optimal_gamma * (temp_pt - pt) + (1 - optimal_gamma) * bt\n    pt = temp_pt\n    forecast[i] = pt\nforecast[-1] = pt + (1 * bt)\nplt.plot(db[:, 0],label = 'real data')\nplt.plot(forecast, label = 'forecast')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ead6867eb85839a2687fb00d5b665f1fba520bf0","_cell_guid":"010e4120-80be-4d25-91ee-3e42a12dc024"},"cell_type":"markdown","source":"As we can see above, the algorithm gives good results on time series that HAVE a trend.\n***"},{"metadata":{"_uuid":"b57332b8a6bb75a43946ab92ab666d10cc929ed5","_cell_guid":"496b5690-9f7e-46cf-a4c5-f4bc7438487d"},"cell_type":"markdown","source":"## 6. Conclusion\n\nIn this notebook it was shown how the ,,Double Exponential Smoothing\" algorithm forecasts based on the smoothing constant ,,alpha'' and ,,gamma\". Moreover, it was presented an implementation of how you can find the optimal ,,alpha'' and ,,gamma\". It was proven that the algorithm gives very good results on time series that have a trend. When dealing with time series, multiple algorithms should be tested to find out which of them gives the minimum MSE. The algorithm with the minimum MSE should be used for further forecasts on that time series.\n\nFor more tutorials check out my [kernels](https://www.kaggle.com/andreicosma/kernels) page.\n\nI hope this notebook helped you in your studies. Keep doing what you like no matter what others think.\n\nReferences: Smaranda Belciug - Time Series course.\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.5","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}