{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7f622086-d740-c509-ebf3-72c03cef9e05"},"source":"I should probably get into the background a little deeper,  I'll do this with a simple exploratory analysis.\n\nThe data is derived from biological experiments in so called Next Generation Sequencing (NGS) .  NGS reads DNA / RNA fragments. The individual raw file is about 300 - 900 mb in size.  They are hosted on NCBI, but without preprocessing not very useful. The uploaded data is preprocessed [92 x 300 ] meaning > 28 GB of data are presented in a 10 mb table. Plenty of loss of information.\n\nBiologist produce data in triplicates. Three columns should cluster together. So the first step should be a rough estimate if the sample preprocessing worked.    The accession numbers for the samples have 6 letters, the first three give an estimation of origin, the second three should be specific. With only the last letter identifying replicates.\n\nI'll run a modified fclustering,  based on euclidian distances . \nFor more details, the following example is much better than what I can come up with.\nhttps://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9fceb97b-a4e0-6b26-b291-162a88a198e4"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # pretty pictures\n#from sklearn.cluster import AgglomerativeClustering  \nfrom scipy.cluster.hierarchy import dendrogram, linkage  # linkage analysis and dendrogram for visualization\nfrom scipy.cluster.hierarchy import fcluster  # simple clustering\nfrom scipy.cluster.hierarchy import inconsistent # inconsistancy metric. see link above why this isn't very good\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33101e9d-b7e5-8ae5-cd26-d6d57b48b464"},"outputs":[],"source":"data = pd.read_csv('../input/SC_expression.csv',index_col = 0 )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0783129e-156d-c60c-735a-5ab98d8dd1aa"},"outputs":[],"source":"Z = linkage(data.transpose(),  method='single', metric='euclidean')  # Performs hierarchical/agglomerative clustering on the condensed distance matrix y."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b36c55e-2951-617a-101f-8ed6ae4ce72d"},"outputs":[],"source":"plt.figure(figsize=(15, 5))\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('sample index')\nplt.ylabel('distance')\ndendrogram(\n    Z,\n    truncate_mode='lastp',\n    p=22,\n    \n    show_leaf_counts=False,  # otherwise numbers in brackets are counts\n    leaf_rotation=90.,\n    leaf_font_size=12.,\n    show_contracted=True,  # to get a distribution impression in truncated branches\n    \n)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a3bb5de-0a81-f6f2-21b5-0d054d6ff17e"},"outputs":[],"source":"clusters = fcluster(Z, 15 , criterion='maxclust')   # clustering wit a maximum of 15 clusters (Corresponding to the 15 groups of accession numbers)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"837fdb54-a7b6-9276-52fe-4922f295246b"},"outputs":[],"source":"clusters"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d28e273-b951-6217-afbb-9c6fe7b0b729"},"outputs":[],"source":"i = 0\ncluster_columns = {}\nfor element in data.columns:\n    cluster_columns[element] = clusters[i]\n    #print element , ' in cluster ' , clusters[i]\n    i+=1\n    \n\nmeta_samples = {}\nfor key, val in cluster_columns.items():\n    # the 6 letter column names correspond to sample origin as accession code. \n    # Considering only the first half of accession gives a set of 15 origins for the data.\n    # corresponding clusters \n    \n    \n    metaval = str(key)[:3]  \n    \n    if not metaval in meta_samples:\n        meta_samples[metaval] = []\n    \n    meta_samples[metaval].append(val)\n    \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23520e81-0359-b510-250a-6acc9239b983"},"outputs":[],"source":"for key, value in meta_samples.items():\n    print(key , value)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"433e1efb-a585-6008-4015-8b476939a362"},"outputs":[],"source":"#  This actually looks OK  \n# the samples SICXXX seems to be without replicates, SARXXX, QCFXXX and FABXXX have one replicate, and so on. \n# extensive accessions are most likely from the same source.\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}