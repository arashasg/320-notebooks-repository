{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib.pyplot import plot\nfrom sklearn.preprocessing import MinMaxScaler\nimport datetime\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first step is to see the data we are processing. For that we can use the method describe that can summarize the dataset's info:"},{"metadata":{"trusted":true},"cell_type":"code","source":"block= 'block_58'\noriginal_data = pd.read_csv('/kaggle/input/daily_dataset/daily_dataset/{}.csv'.format(block))\noriginal_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"max_data = original_data.loc[original_data.groupby('LCLid').pipe(lambda group: group.energy_max.idxmax(skipna=True))][['LCLid','day','energy_max']]\nmin_data = original_data.loc[original_data.groupby('LCLid').pipe(lambda group: group.energy_max.idxmin(skipna=True))][['LCLid','day','energy_min']]\n# original_data.describe()\n\ndata = original_data.groupby('LCLid').agg({'energy_median': ['mean'], 'energy_mean': ['mean'], 'energy_sum': ['sum']})\ndata = data.merge(max_data, left_on='LCLid', right_on='LCLid',suffixes=('_left', '_max'))\ndata = data.merge(min_data, left_on='LCLid', right_on='LCLid',suffixes=('_max', '_min'))\ndata['day_max'] = pd.to_datetime(data['day_max']).dt.dayofweek\ndata['day_min'] = pd.to_datetime(data['day_min']).dt.dayofweek\n\n# data = pd.concat([data,pd.get_dummies(data['day_min'], prefix='day_min')],axis=1).drop(columns=['day_min'])\n# data = pd.concat([data,pd.get_dummies(data['day_max'], prefix='day_max')],axis=1).drop(columns=['day_max'])\ndata['min_max_ratio'] = data.pipe(lambda group: group.energy_min/ group.energy_max)\n# print(original_data[(original_data['LCLid']=='MAC000094')])\n\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import pairwise_distances_argmin_min\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nX = scaler.fit_transform(data.drop(columns=['LCLid']))\n\nNc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in Nc]\nscore = [kmeans[i].fit(X).score(X) for i in range(len(kmeans))]\n\nplt.plot(Nc,score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=4).fit(X)\ncentroids = kmeans.cluster_centers_\nprint(centroids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustered_data = pd.concat([data,pd.DataFrame(kmeans.predict(X))],axis=1).sort_values(by=[0])\nclustered_data = clustered_data.rename(columns={0: 'Cluster'})\nclustered_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hourly_data = pd.read_csv('/kaggle/input/hhblock_dataset/hhblock_dataset/{}.csv'.format(block))\n\ndef create_plot(LCLid, start_date=None, end_date=None, ax=None, title=None):\n    plot_data = hourly_data[(hourly_data['LCLid']==LCLid)].set_index('day').drop(columns=['LCLid'])\n    plot_data = plot_data.stack().reset_index().rename(columns={0: LCLid,'level_1': 'time','day':'date'})\n    plot_data['time'] = plot_data['time'].apply(lambda x: x.replace('hh_',''))\n    plot_data['datetime'] = plot_data[['date','time']].apply(lambda x: pd.to_datetime(x['date'])+datetime.timedelta(minutes=int(x['time'])*30),axis=1)\n    plot_data = plot_data.drop(columns=['date','time'])\n    \n    if start_date:\n        plot_data = plot_data[(plot_data['datetime'] >= pd.to_datetime(start_date))] \n    if end_date:\n        plot_data = plot_data[(plot_data['datetime'] <= pd.to_datetime(end_date))]  \n        \n    if len(plot_data.index>0):\n        plot_data = plot_data.set_index('datetime')\n        plot = plot_data.plot(ax=ax, title=title, figsize = (20,6))\n        print(\"Processing {LCLid}, {title}\".format(**{'LCLid':LCLid, 'title':title}))\n        return plot\n    \n    print(\"[WARNING] LCLid: {LCLid} has no data between dates: {start_date}-> {end_date}\".format(**{'LCLid': LCLid, 'start_date': start_date, 'end_date': end_date}))\n    return None\n    \n\n# hourly_data.head()\nax = None\ncluster = 0\nstart_date='2014-02-01'\nend_date='2014-02-07'\ntitle = \"Cluster: {}\".format(str(cluster))\nfor index, consumer_row in clustered_data[['LCLid','Cluster']].iterrows():\n    plot_new_cluster = cluster != consumer_row['Cluster']\n    consumer_id, cluster = consumer_row['LCLid'], consumer_row['Cluster']\n    aux = create_plot(consumer_id,start_date=start_date,end_date=end_date,ax=ax,title=title)\n    if aux:\n        ax = aux\n    if plot_new_cluster:\n        ax = None\n        title = \"Cluster: {}\".format(str(cluster))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}