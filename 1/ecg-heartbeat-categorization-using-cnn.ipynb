{"cells":[{"metadata":{},"cell_type":"markdown","source":"## ECG Heartbeat Categorization\n\n> This dataset is composed of two collections of heartbeat signals derived from two famous datasets in heartbeat classification, the MIT-BIH Arrhythmia Dataset and The PTB Diagnostic ECG Database."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing dataset from drive\n\ndata = pd.read_csv(\"../input/heartbeat/mitbih_train.csv\", header=None)\ndf = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \nnull_col = []\n\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n  if df[i].isna().mean()*100 > 0:\n    null_col.append(i)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since data does'nt contain any null values, we can move further"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = []\nsns.countplot(x=187, data = df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Here this bar graph easily shows how data is imbalanced. More than 80% data is in class 0. So, first, we have to balance th data in to get more precise predictions.\n\n> For balancing the data I'm using undersampling in which we will reduce the rows of class 0 to the number compareble to others/"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_1 = df[df[187]==1.0]\nclass_2 = df[df[187]==2.0]\nclass_3 = df[df[187]==3.0]\nclass_4 = df[df[187]==4.0]\nclass_0 = df[df[187]==0.0].sample(n = 8000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.concat([class_0, class_1, class_2, class_3, class_4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=187, data = new_df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now for visualising each class, here is plot of any random sample of hearbeat in each class."},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize=(25,2))\n\nfor i in range(5):\n  ax[i].plot(new_df[new_df[187]==float(i)].sample(1).iloc[0,:186])\n  ax[i].set_title('Class: '+str(i))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(new_df.drop([187], axis=1), new_df[187], test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential,utils\nfrom tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = Sequential()\n\nclf.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\nclf.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation='relu')) \nclf.add(Conv1D(filters=128, kernel_size=(5,), padding='same', activation='relu'))    \n\nclf.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\nclf.add(Dropout(0.5))\n\nclf.add(Flatten())\n\nclf.add(Dense(units = 512, activation='relu'))\nclf.add(Dense(units = 1024, activation='relu'))\n\nclf.add(Dense(units = 5, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = clf.fit(X_train, y_train, epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\n\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, color='red', label='Training acc')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny_lbl = [np.where(i == np.max(i))[0][0] for i in y_pred]\nmat = confusion_matrix(y_test, y_lbl)\nfig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(mat, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Measure the Accuracy Score\n\nfrom sklearn import metrics\n\nprint(\"Accuracy score of the predictions: {0}\".format(metrics.accuracy_score(y_lbl, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As we can see above CNN got accuracy of 96.6%, now we can predict the vaalues for our test dataset."},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/heartbeat/mitbih_test.csv\", header=None)\ntest_df = pd.DataFrame(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = []\nsns.countplot(x=187, data = test_df) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize=(25,2))\n\nfor i in range(5):\n  ax[i].plot(test_df[test_df[187]==float(i)].sample(1).iloc[0,:186])\n  ax[i].set_title('Class: '+str(i))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X = test_df.drop([187], axis=1) \ntest_y = test_df[187]\n\ntest_X = np.array(test_X).reshape(test_X.shape[0], test_X.shape[1], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_y = clf.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ntest_lbl_y = [np.where(i == np.max(i))[0][0] for i in test_pred_y]\nmat = confusion_matrix(test_y, test_lbl_y)\nfig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(mat, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Measure the Accuracy Score\n\nfrom sklearn import metrics\n\nprint(\"Accuracy score of the predictions: {0}\".format(metrics.accuracy_score(test_lbl_y, test_y)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> And here our CNN got us 96.5% accuracy on test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}