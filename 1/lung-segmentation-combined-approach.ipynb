{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"source":"Credits: Code and technique combined from the following 3 sources\n* https://www.kaggle.com/toregil/a-lung-u-net-in-keras\n* https://www.kaggle.com/irrwitz/cnn-with-keras\n* https://www.kaggle.com/arnavkj95/data-science-bowl-2017/candidate-generation-and-luna16-preprocessing/run/755223\n\nThis model combines preprocessing of the images with a CNN Sequential model and data augmentation by applying random rotation to the images and masks. The accuracy on the test set is 98.5%","cell_type":"markdown","metadata":{"_cell_guid":"a0213dc0-ef8a-4623-86b4-1f7635c48cac","_uuid":"083d07d921aa385118602bf8c4c1c072209617bc"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"df8ae4a4-e48d-4582-8952-fc76f2e1594c","_uuid":"7b77e37bc7a3a36dfb672857c799fcece9afc275"},"source":"import tensorflow as tf\nimport numpy as np\nnp.random.seed(123)\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.io import imread\nfrom tensorflow.python.framework import ops\nimport math\n\nimport pandas as pd\nimport keras.backend as K\n\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Dense, Dropout, Activation, \\\n                         Flatten, Convolution2D, MaxPooling2D, \\\n                         BatchNormalization, UpSampling2D\nfrom keras.utils import np_utils\nfrom scipy import ndimage\nfrom keras.optimizers import Adam, SGD\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\nfrom skimage.measure import label,regionprops, perimeter\nfrom skimage.filters import roberts, sobel\nfrom skimage import measure, feature\nfrom skimage.segmentation import clear_border"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4b5dba8b-d10c-4a2b-b5c6-bc084bec4f99","_uuid":"f581c8ef32a5c9b2ced025d26ce411c52b6d4bd5"},"source":"K.set_image_dim_ordering('th')\n# helper function to load the image and downsample it by 4\njimread = lambda x: np.expand_dims(imread(x)[::4, ::4],0)\n#load images and masks\ndata_path = os.path.join('..', 'input')\n\nall_images = glob(os.path.join(data_path, '2d_images', '*.tif'))\nall_masks = ['_masks'.join(c_file.split('_images')) for c_file in all_images]\nprint(len(all_masks), 'matching files found')"},{"source":"* Read the inages and masks, which are now at 1/4th resolution, into a stack.\n* Scale all mask values to 0-1.\n* Preprocess the images by first creating true/false map of the Houndsfield Unit values. \n* clear_border gets rid of the body and CT machine components.\n* By multipying the original images by the cleared true/false images, we get the a rough lung segmentation.","cell_type":"markdown","metadata":{"_cell_guid":"9305d528-3c2a-4175-af35-ca4e08e8ce37","_uuid":"a752659bdd03d20b6a6dae7ccb7db1a7258d666c"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"1b84e7e4-6992-42a6-9b10-9c21b6d79086","_uuid":"008122c6f49337a3eeace672830186b91262812b"},"source":"images = np.stack([jimread(i) for i in all_images], 0)\nmasks = np.stack([jimread(i) for i in all_masks], 0) / 255.0\n\n#Preprocess\npreImages = np.stack([imread(i)[::4, ::4] for i in all_images], 0)\nfor idx,image in enumerate(preImages):\n    binary = image < -400\n    cleared = clear_border(binary)\n    preImages[idx] = preImages[idx] * cleared\n    \n#plt.imshow(preImages[0])\nimages = np.expand_dims(preImages, 1)\nprint(images.shape)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"078ce3ad-9853-4d13-988c-358b4ebb1efb","_uuid":"3ada0d028b765beca8f23b53362a837afcbf1ddf"},"source":"X_train, X_test, y_train,  y_test = train_test_split(images, masks, test_size=0.1)\nprint('Training input is', X_train.shape)\nprint('Training output is {}, min is {}, max is {}'.format(y_train.shape, y_train.min(), y_train.max()))\nprint('Testing set is', X_test.shape)"},{"source":"The generator expands our image set by giving the images a random rotation. By using the same random seed, the images and masks will still correlate.","cell_type":"markdown","metadata":{"_cell_guid":"0b9da092-e7f7-4d72-9020-22be1af817c5","_uuid":"5073c11bb50a89e905255fcec4565cf1ae35d51f"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"294b4fbe-2c8f-4d32-b459-d0e8fcecdc43","_uuid":"1f25d603cd893497fec70487eaccff4fdb8c7a72"},"source":"SEED=42\n#Data augmentation\ndef image_augmentation_generator(xtrain, ytrain, batch_size):\n    data_generator = ImageDataGenerator(\n            rotation_range=45).flow(xtrain, xtrain, batch_size, seed=SEED)\n    mask_generator = ImageDataGenerator(\n           rotation_range=45).flow(ytrain, ytrain, batch_size, seed=SEED)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch"},{"source":"Lets take a look at a preprocessed image and the corresponding mask.","cell_type":"markdown","metadata":{"_cell_guid":"9700a75f-20b6-4e5c-808d-ba4e6d365410","_uuid":"d3a7cf1e830d419a8fba0647d741a11b521c2f13"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"f06dbd8e-1a49-4569-bd7d-ceb2518a377d","_uuid":"00d1192a510e356f8f16a6f326ada0d7dfc01972"},"source":"first_image = images[0]\nfirst_mask = masks[0]\nfig, (ax1,ax2) = plt.subplots(1,2)\nax1.imshow(first_image[0])\nax2.imshow(first_mask[0])"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"b33baee6-49be-4eaa-87c1-432ced8b9ff5","_uuid":"b73207c7f415195c4115bac63e0a5baf379b9b41"},"source":"# Create a deep nn\nmodel = Sequential()\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3, 3), \n                        activation='relu', \n                        input_shape=images.shape[1:],\n                        padding='same'\n                        ))\nmodel.add(Convolution2D(filters=64, \n                        kernel_size=(3, 3), \n                        activation='sigmoid', \n                        input_shape=images.shape[1:],\n                        padding='same'\n                        ))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Convolution2D(filters=1, \n                        kernel_size=(3, 3), \n                        activation='sigmoid', \n                        input_shape=images.shape[1:],\n                        padding='same'\n                        ))\nmodel.add(UpSampling2D(size=(2,2)))\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer='rmsprop',\n             metrics=['accuracy','mse'])\n#print(model.summary())"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4f358885-0ada-4a3b-a6c1-f17d819c0bdc","_uuid":"af98f8bc79a2a18856d87888888e9832cbda4a80"},"source":"history = model.fit_generator(image_augmentation_generator(X_train, y_train, 16),\n                           steps_per_epoch = 60,\n                           validation_data = (X_test, y_test),\n                           epochs=10, verbose=1)"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"b4d26578-2625-4fd9-b053-a44d346b6ae1","_uuid":"493808c6cddc13082bbd06682d0ee71b2ee5f70c"},"source":"#Graphs of the accuracy and loss\nfig, ax = plt.subplots(1,2)\nax[0].plot(history.history['acc'], 'b')\nax[0].set_title('Accuracy')\nax[1].plot(history.history['loss'], 'r')\nax[1].set_title('Loss')"},{"source":"","cell_type":"markdown","metadata":{"collapsed":true,"_cell_guid":"adb34d27-12dc-4838-aaf5-0238c16c5f88","_uuid":"9b6b71305fcca1b60deabc1820f9164ee449f212"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"f3871e67-786c-4925-81e2-28286e04640f","_uuid":"114abb47ff01db7d5417ff6543d7f7f680af58cf"},"source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize = (20, 8))\nax1.imshow(X_test[0,0])\nax2.imshow(y_test[0,0])\nax3.imshow(model.predict(X_test)[0,0], cmap=\"Greys\")\nax4.imshow(X_test[1,0])\nax5.imshow(y_test[1,0])\nax6.imshow(model.predict(X_test)[1,0], cmap=\"Greys\")"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"17519761-2e67-4420-9e3a-739a9047596f","_uuid":"2c888b10aea6c54dd01e434face1ada39474d0bf"},"source":"scores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"5ca65b4b-f80f-49ce-9ce1-68576c15d8ef","_uuid":"808858146945b71cf48e2f5c186aa97f4416aca4"},"source":"# serialize model to JSON\nmodel_json = model.to_json()\nmodelFileName = \"kaggle_model_\"\nwith open(modelFileName + \".json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(modelFileName + \".h5\")\nprint(\"Saved model to disk\")"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"0874b123-bed8-4220-aa9d-decc5ef01523","_uuid":"fdb08b269adbdee8148b409963aa953b0b105d63"},"source":""}]}