{"cells":[{"metadata":{},"cell_type":"markdown","source":"# some of the most needed code snippets \nI'm will put some usefull and most repetitive code snippets in this notebook.<br>\nfeel free to fork this notebook and complete it:)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='red'>you can skip this part of the notebook. it's only for creating some dummy data</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a sample csv file \nsize = 150\ny = np.random.choice(['L1', 'L2', 'L3'], size=size, p=[0.1, 0.6, 0.3]) # labels for our dummy data\ncat1 = np.random.choice(['a','b','c','d', np.nan], size=size, p=[0.2,0.1,0.2,0.45, 0.05])\ncat2 = np.random.choice([0,1, np.nan], size=size, p=[0.5,0.45, 0.05])\n\ndf = pd.DataFrame({'x1': np.random.randn(size), 'x2' : np.random.randn(size),'cat1': cat1, 'cat2':cat2, 'y': y})\n\ndf.to_csv('sample.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Dataset"},{"metadata":{},"cell_type":"markdown","source":"### CSV File"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"csv_path = 'sample.csv'\ndf = pd.read_csv(csv_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### opening Image Files from Zip\n\nnot recommended for large image datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"zip_file_path = 'zip.zip' # or 'your_npz.npz'\n# uncomment the line below\n# images = np.load(zip_file_path) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting Zip file"},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n# uncomment the folowing lines\n# with zipfile.ZipFile(zip_file_path) as z:\n#     z.extractall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# set the figure sizes\nplt.figure(figsize=(10,5))\nsns.set(rc={'figure.figsize':(10,5)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['x1'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### bar chart\nfor label y"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.x2, df.y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### pie chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels, counts = np.unique(df.y,return_counts=True)\nplt.pie(counts, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling <font color='blue'> Nan</font> Vaules"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n# here I changed the missing value to 'nan' but most of the times default is good\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent') \ndf[['cat1', 'cat2']] = imputer.fit_transform(df[['cat1','cat2']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='red'>Note: if your feature is 1-D array you shall use reshape(1,-1) before using it with imputer</font>"},{"metadata":{},"cell_type":"markdown","source":"## Normalizing"},{"metadata":{},"cell_type":"markdown","source":"### MinMax"},{"metadata":{"trusted":true},"cell_type":"code","source":"minmax = preprocessing.MinMaxScaler((0,1))\ndf[['x1','x2']] = minmax.fit_transform(df[['x1','x2']])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = df.select_dtypes('object').columns\n\n\nle = preprocessing.LabelEncoder()\nfor col in categorical_features:\n    df[col] = le.fit_transform(df[col])\n    \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding another dummy categorical feature\ngender = np.random.choice(['Male', 'Female', 'another'], size=size, p=[0.4, 0.4, 0.2])\ndf['gender'] = gender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\n\noht = pd.DataFrame(ohe.fit_transform(df[['gender']]))\n\noht.index = df.index\n\nnum_df = df.drop(['gender'], axis=1)\n\ndf = pd.concat([num_df, oht],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df.y\nX = df.drop(['y'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('train shape: {}\\ntest shape: {}'.format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using mean squared error\nfrom sklearn.metrics import mean_squared_error\n\ndef calculate_error(y_pred, y_true):\n    print(mean_squared_error(y_pred, y_true))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Models"},{"metadata":{},"cell_type":"markdown","source":"### RidgeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\n\nmodel = RidgeClassifier(random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SGDClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nmodel = SGDClassifier(random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble"},{"metadata":{},"cell_type":"markdown","source":"### Random forrest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nmodel = AdaBoostClassifier(random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GradientBoosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nmodel = GradientBoostingClassifier(random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier(max_leaf_nodes=200, random_state=0)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\ncalculate_error(preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# create submission csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_submission(test_path, preds, path='submission.csv'):    \n    '''\n    test_path: test csv file\n    preds    : predicted label from your model\n    path     : where you want to save the csv file\n    '''\n    test_df = pd.read_csv(test_path)\n    test_df['label_column'] = preds\n    test_df.to_csv(path, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}