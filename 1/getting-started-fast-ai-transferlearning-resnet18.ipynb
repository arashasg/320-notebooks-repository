{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Referred from https://www.kaggle.com/kenseitrg/simple-fastai-exercise**"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from pathlib import Path \nfrom fastai import *\nfrom fastai.vision import *\nimport torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialise directory path"},{"metadata":{"trusted":true},"cell_type":"code","source":"# stores Path of input directory to be used as an argument in fetching test and train \ndata_folder = Path(\"../input\")\ndata_folder.ls()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load train and test csvs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read CSV train and test files using Pandas\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load test images using from_df. Get the filenames in cols of test_df with folder in front of them\n# Read more: https://docs.fast.ai/vision.data.html#ImageList.from_df\ntest_img = ImageList.from_df(test_df, path=data_folder/'test', folder='test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# do_flip = True --> a random flip is applied with probability 0.5\n# flip_vert = True --> requires do_flip = True, the image will be flipped vertically or rotated by 90 degrees\n# max_rotate = 10.0 --> random rotation between -10 to +10 with probability of p_affine\n# max_zoom = 1.1 --> random zoom applied between 1 and 1.1 with probability of p_affine\n# max_lighting = 0.2 --> lighting and contrast of magnitude between -0.2 and 0.2 applied with probability of p_lighting\n# max_wrap = 0.2 --> symmetric warp of magnitude between -0.2 and 0.2 with probability of p_affine\n# p_affine = 0.75 --> 0.75 probability used to apply max_rotate, max_zoom, max_wrap\n# p_lighting = 0.75 --> 0.75 probability used to apply max_lighting\n# Read more: https://docs.fast.ai/vision.transform.html#get_transforms\ntrfm = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load training images and preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = (ImageList.from_df(train_df, path=data_folder/'train', folder='train')  # load training images using from_df()\n        .split_by_rand_pct(0.01)                                                    # randomly puts 0.01 = 1% of data into validation set\n        .label_from_df()                                                            # fetches all labels with corresponding images. Only works with from_df()\n        .add_test(test_img)                                                         # adds test images\n        .transform(trfm, size=128)                                                  # transformation are applied to the training set\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))                 # creates DataBunch with batchsize = 64, and device = cuda index 0 GPU\n        .normalize(imagenet_stats)                                                  # using imagenet_stats to normalize the dataset. Other valid values are cifar_stats and mnist_stats\n       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display sample data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displays 2 rows of images from the training dataset\ntrain_img.show_batch(rows=2, figsize=(7,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transfer learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using resnet18 base architecture for transfer learning and metrics as error_rate and accuracy.\n# The various models fastai offers for vision are torch models (https://pytorch.org/docs/stable/torchvision/models.html) + fastai models (https://docs.fast.ai/vision.models.html)\n# Read more: https://docs.fast.ai/vision.learner.html#cnn_learner\nlearn = cnn_learner(train_img, models.resnet18, metrics=[error_rate, accuracy])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit model using 1cycle policy\n### Read more: https://sgugger.github.io/the-1cycle-policy.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 3e-02\nlearn.fit_one_cycle(5, slice(lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.has_cactus = preds.numpy()[:, 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission_resnet_18.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}