{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Import all required packages**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape # get shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Analysis**\n\nANALYZE DATA USING PLOTS TO SHOW RELATIONSHIP BETWEEN DIFFERENT VARIABLES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',data = data) # countplot to check how many survived (1) and not survived (0).","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',hue = 'Sex',data = data) # check how many male/female are survived (1) and not survived (0). \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',hue = 'Pclass', data = data) # check pasangers are from which class.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Age'].hist(bins = 10) # histogram of Age (agewise frequency of pasanger in titanic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'SibSp',data = data) # get countplot of 'SibSp'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info() # get data info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Wrangling**\nCLEAN DATA BY REMOVING NAN VALUES AND UNNECESSARY COLUMNS IN DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull() # check null values in data (False = not null, True = null)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()  # get sum of null values in each column.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.isnull()) # heatmap where 'Age' and 'Cabin' has more null values.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Age'] = data['Age'].fillna(data['Age'].mean()) # null values in 'Age' is replaced by mean.\ndata = data.drop(['Cabin'],axis = 1) # drop 'Cabin' which is having more null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape # get shape (1 column dropped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace = True) # remaining null values removed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum() # check for the null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.isnull()) # heatmap for null values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['PassengerId','Name','Ticket'],axis = 1,inplace = True)  # drop unwanted column from data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:,.2f}'.format\ndata.corr() # get correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(),annot = True,fmt = '.2f') # visualize correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get dummies for 'Sex', 'Embarked','Pclass'\nsex = pd.get_dummies(data['Sex'],drop_first = True) \nembarked = pd.get_dummies(data['Embarked'],drop_first = True)\npclass = pd.get_dummies(data['Pclass'],drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([data,sex,pclass,embarked],axis = 1) # add it into data\ndata.drop(['Pclass','Sex','Embarked'],axis = 1, inplace = True) # remove previous one","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Training**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(['Survived'],axis = 1) # get independent variable\ny = data['Survived'] # get dependent (target) variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform train-test-split with test_size of 0.2 \nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data scaling\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(max_iter = 150,n_jobs = 1)  # model building\nmodel.fit(x_train,y_train) # model training\ny_pred = model.predict(x_test) # get prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance evaluation \n\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Accuracy:\",round(accuracy_score(y_test,y_pred)*100,2),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Test Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/titanic/test.csv') # load test data\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape # get shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum() # check null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# handling null values\n\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())  # replace null values\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean()) # replace null values\ntest_data.drop(['Cabin'],axis = 1, inplace = True) # drop 'Cabin' having more null value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum() # check null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get dummies \n\ntsex = pd.get_dummies(test_data['Sex'],drop_first = True)\ntembarked = pd.get_dummies(test_data['Embarked'],drop_first = True)\ntpclass = pd.get_dummies(test_data['Pclass'],drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_data = pd.concat([test_data,tsex,tpclass,tembarked],axis = 1) # add it into data\nt_data = t_data.drop(['Pclass','PassengerId','Name','Sex','Ticket','Embarked'],axis = 1) # drop unwanted coulumn\nt_data = sc.fit_transform(t_data) # data scaling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(t_data) # make prediction on test data\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.shape # check result shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add it to csv file\n\nid =  test_data['PassengerId']\nd = {'PassengerId':id,'Survived':result}\ndf = pd.DataFrame(d)\ndf.to_csv('TitanicSubmission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}