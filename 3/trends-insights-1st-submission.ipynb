{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# **TReNDS : EDA + Visualization + Models** \n\n\n\n## **Introduction**\n\n\n[TReNDS Neuroimaging](https://www.kaggle.com/c/trends-assessment-prediction) competition has been recently launched at Kaggle. We can find the evaluation page [here](https://www.kaggle.com/c/trends-assessment-prediction/overview/evaluation)\n\nHuman brain research is among the most complex areas of study for scientists. We know that age and other factors can affect its function and structure, but more research is needed into what specifically occurs within the brain. With much of the research using MRI scans, data scientists are well positioned to support future insights. In particular, neuroimaging specialists look for measurable markers of behavior, health, or disorder to help identify relevant brain regions and their contribution to typical or symptomatic effects.\n\nIn this competition, we will predict multiple assessments plus age from multimodal brain MRI features. \n\n\n"},{"metadata":{},"cell_type":"markdown","source":"![TReNDS](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1537731%2Fa5fdbe17ca91e6713d2880887232c81a%2FScreen%20Shot%202019-12-09%20at%2011.25.31%20AM.png?generation=1575920121028151&alt=media)"},{"metadata":{},"cell_type":"markdown","source":"\n**I hope you find this notebook useful and your <font color=\"red\"><b>UPVOTES</b></font> keep me motivated**\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n# **Table of Contents** \n\n1.\t[Import libraries](#1)\n2.\t[Read datasets](#2)\n3.  [Data Exploration](#3)\n   - 3.1 [Shape of the data](#3.1)\n   - 3.2 [Preview the data](#3.2)\n   - 3.3 [Check for missing values](#3.3)\n4.  [Data Visualization](#4)\n   - 4.1 [Data Visualization of Features](#4.1)\n         - 4.1.1 [age](#4.1.1)\n         - 4.1.2 [domain1_var1](#4.1.2)\n         - 4.1.3 [domain1_var2](#4.1.3)\n         - 4.1.4 [domain2_var1](#4.1.4)\n         - 4.1.5 [domain2_var2](#4.1.5)\n   - 4.2 [Correlation Heatmap](#4.2)\n   - 4.3 [Pair Plot](#4.3)\n5. [Modelling](#5)\n6. [Submission](#6)     \n\n   \n"},{"metadata":{},"cell_type":"markdown","source":"# **1. Import libraries** <a class=\"anchor\" id=\"1\"></a>\n\n[Table of Contents](#0.1)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ignore warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import general packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline\ncolor = sns.color_palette()\n\n\n# algorithms\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n# modeling helper functions\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n\n# to read / write access to some common neuroimaging file formats\n## for more information, please visit : https://pypi.org/project/nibabel/\nimport nibabel\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# print all files in the data folder\nbase_url = '/kaggle/input/trends-assessment-prediction'\nprint(os.listdir(base_url))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Read datasets** <a class=\"anchor\" id=\"2\"></a>\n\n[Table of Contents](#0.1)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nloading_df = pd.read_csv(base_url +'/loading.csv')\nsample_submission = pd.read_csv(base_url +'/sample_submission.csv')\ntrain_df = pd.read_csv(base_url +'/train_scores.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Data Exploration** <a class=\"anchor\" id=\"3\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"## **3.1 Shape of the data**  <a class=\"anchor\" id=\"3.1\"></a>\n\n[Table of Contents](#0.1)\n\nWe will begin our data exploration by checking the shape of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Size of loading_df : {loading_df.shape}')\nprint(f'Size of sample_submission : {sample_submission.shape}')\nprint(f'Size of train_df : {train_df.shape}')\nprint(f'Size of test set : {len(sample_submission)/5}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.2 Preview the data**  <a class=\"anchor\" id=\"3.2\"></a>\n\n[Table of Contents](#0.1)\n\n\nNow, let's preview the data to gain more insights about the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preview(df):\n    print(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preview(loading_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preview(sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preview(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.3 Check for missing values**  <a class=\"anchor\" id=\"3.3\"></a>\n\n[Table of Contents](#0.1)\n\n\nNow, let's check for missing values in training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_train_df = train_df.isnull().mean() * 100\nmissing_train_df.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loading_df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, `loading_df` and `sample_submission` do not have any missing values. "},{"metadata":{},"cell_type":"markdown","source":"# **4. Data Visualization** <a class=\"anchor\" id=\"4\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"## **4.1 Data Visualization of features** <a class=\"anchor\" id=\"4.1\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_labels = list(train_df.columns[1:])\ntarget_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will check the distribution of target variables in training set. We will exclude `Id` from the training set."},{"metadata":{},"cell_type":"markdown","source":"### **4.1.1 age** <a class=\"anchor\" id=\"4.1.1\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['age']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='g')\nplt.xlabel('Age')\nplt.ylabel('Number of patients')\nplt.title('Age distribution of patients', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age does not contain any missing values."},{"metadata":{},"cell_type":"markdown","source":"### **4.1.2 domain1_var1** <a class=\"anchor\" id=\"4.1.2\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['domain1_var1']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='c')\nplt.xlabel('domain1_var1')\nplt.ylabel('Number of patients')\nplt.title('domain1_var1 distribution', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that `domain1_var1` distribution is approximately normal. So, we will fill the missing values with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['domain1_var1'].fillna(train_df['domain1_var1'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4.1.3 domain1_var2** <a class=\"anchor\" id=\"4.1.3\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['domain1_var2']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='pink')\nplt.xlabel('domain1_var2')\nplt.ylabel('Number of patients')\nplt.title('domain1_var2 distribution', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`domain1_var2` is skewed. So, we will fill missing values with median."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['domain1_var2'].fillna(train_df['domain1_var2'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4.1.4 domain2_var1** <a class=\"anchor\" id=\"4.1.4\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['domain2_var1']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='y')\nplt.xlabel('domain2_var1')\nplt.ylabel('Number of patients')\nplt.title('domain2_var1 distribution', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`domain2_var1` is approximately normal. So, we will fill missing values with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['domain2_var1'].fillna(train_df['domain2_var1'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4.1.5 domain2_var2** <a class=\"anchor\" id=\"4.1.5\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['domain2_var2']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='r')\nplt.xlabel('domain2_var2')\nplt.ylabel('Number of patients')\nplt.title('domain2_var2 distribution', fontsize = 16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`domain2_var2` is approximately normal. So, we will fill missing values with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['domain2_var2'].fillna(train_df['domain2_var2'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in training set."},{"metadata":{},"cell_type":"markdown","source":"## **4.2 Correlation Heatmap**  <a class=\"anchor\" id=\"4.2\"></a> \n\n[Table of Contents](#0.1)\n\n\nCorrelation Heatmap is used to visualize feature interactions in training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train_df.columns[1:]\ncorrelation = train_df[cols].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.zeros_like(correlation)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(12,8))\n    ax = sns.heatmap(correlation, mask=mask, vmax=.3, square=True, annot=True, cmap='YlGnBu', fmt='.2f', linecolor='white')\n    ax.set_title('Correlation Heatmap of training dataset')\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n    ax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4.3 Pair Plot**  <a class=\"anchor\" id=\"4.3\"></a> \n\n[Table of Contents](#0.1)\n\n\nWe will draw pairplot to visualize relationship between the target variables. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_df[cols], kind='scatter', diag_kind='hist', palette='Rainbow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Observations** \n\n\nFrom the above heatmap and pairplot, we can conclude that-\n\n- `age` is positively correlated with `domain1_var1` and `domain2_var1`.\n\n- `domain2_var1` and `domain2_var2` are positively correlated."},{"metadata":{},"cell_type":"markdown","source":"# **5. Modelling** <a class=\"anchor\" id=\"5\"></a>\n\n[Table of Contents](#0.1)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ids = sorted(loading_df[loading_df['Id'].isin(train_df.Id)]['Id'].values)\ntest_ids = sorted(loading_df[~loading_df['Id'].isin(train_df.Id)]['Id'].values)\npredictions = pd.DataFrame(test_ids, columns=['Id'], dtype=str)\nfeatures = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(loading_df, train_df, on='Id')\nX_train = data.drop(list(features), axis=1).drop('Id', axis=1)\ny_train = data[list(features)]\nX_test = loading_df[loading_df.Id.isin(test_ids)].drop('Id', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Neural Net\" ]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressors = [\n    LinearRegression(),\n    DecisionTreeRegressor(max_depth=5),\n    RandomForestRegressor(max_depth=5, n_estimators=10, max_features=1),\n    MLPRegressor(alpha=1, max_iter=1000),\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterate over classifiers and calculate cross-validation score\nfor name, reg in zip(names, regressors):\n    scores = cross_val_score(reg, X_train, y_train, cv = 5, scoring='neg_mean_absolute_error')\n    print(name , ':{:.4f}'.format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Random Forest results in lowest negative MAE. So, we will use it for submission."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# **6. Submission** <a class=\"anchor\" id=\"6\"></a>\n\n[Table of Contents](#0.1)\n"},{"metadata":{},"cell_type":"markdown","source":"## To be continued. Please visit this space again."},{"metadata":{},"cell_type":"markdown","source":"[Go to Top](#0)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}