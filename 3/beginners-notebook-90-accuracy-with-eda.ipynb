{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><h1 style=\"color:green\">Don't forget to upvote if you like it! It's free! :)</h1></center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Contents:\n1. Include Libraries\n2. Import DataSet\n3. EDA(Exploratory Data Analysis)\n4. Handle Missing Value\n5. Feature Engineering by OneHotEncoding\n6. Logistic Regression\n7. Hyperparameter Tunning\n8. Train Random Forest Classifier\n9. Final Submittion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statistics import mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load DataSet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examine Dataset\n## Look In to every column one by one ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Survived']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived', hue='Sex', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wow! 'Sex' looks like a very strong explanatory variable, and it can be our choice for our single feature Logistic Regression model!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### You can also find null values by plotting it on graph","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.isnull(), yticklabels = False, cmap='plasma');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can skip arguments other than x, cmap is styling the heatmap\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Pclass']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Name.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'].hist(bins=40);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can always use value_counts to check on data, visualization is just another option ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['SibSp'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['SibSp'])\nplt.title('Count plot for SibSp');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Parch'])\nplt.title('Count plot for Parch');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Ticket.value_counts(dropna=False, sort=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare'].hist(bins=50)\nplt.ylabel('Price')\nplt.xlabel('Index')\nplt.title('Fare Price distribution');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.Cabin.value_counts(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Embarked'])\nplt.title('Count plot for Embarked');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Look in to relationships among dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.corr(), annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### annot argument is mandatory as you also need data value in each cell\n### As you can see that Survived as max relation with Pclass, lets vizualize it in chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived', hue='Pclass', data=train)\nplt.title('Count plot for Pclass categorized by Survived');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pclass and age, as they had max relation in the entire set we are going to replace missing age values with median age calculated per class","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Let's Fix data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_group = train.groupby('Pclass')['Age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_group.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_group.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.Age.isnull(), 'Age'] = train.groupby(\"Pclass\").Age.transform('median')\n\ntrain[\"Age\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.isnull(), yticklabels = False, cmap='plasma');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Sex'][train['Sex'] == 'male'] = 0\ntrain['Sex'][train['Sex'] == 'female'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You need to do the same changes in test dataset aslo...So lest merge test and train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Survived'] = np.nan\nfull = pd.concat([df, test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Embarked'] = full['Embarked'].fillna(mode(full['Embarked']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert 'Sex' variable to integer form!\nfull[\"Sex\"][full[\"Sex\"] == \"male\"] = 0\nfull[\"Sex\"][full[\"Sex\"] == \"female\"] = 1\n\n# Convert 'Embarked' variable to integer form!\nfull[\"Embarked\"][full[\"Embarked\"] == \"S\"] = 0\nfull[\"Embarked\"][full[\"Embarked\"] == \"C\"] = 1\nfull[\"Embarked\"][full[\"Embarked\"] == \"Q\"] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(full.corr(), annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### OK, if we look closely, corr(Age, Pclass) is the highest correlation in absolute numbers for 'Age', so we'll use Pclass to impute the missing values:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Age'] = full.groupby(\"Pclass\")['Age'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Also, corr(Fare, Pclass) is the highest correlation in absolute numbers for 'Fare', so we'll use Pclass again to impute the missing values!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Fare']  = full.groupby(\"Pclass\")['Fare'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Cabin'] = full['Cabin'].fillna('U')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"full['Cabin'].unique().tolist()[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Did you recognize something? yes, We can get the alphabets(first letter) by running regular expression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Cabin'] = full['Cabin'].map(lambda x:re.compile(\"([a-zA-Z])\").search(x).group())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'T':8, 'U':9}\nfull['Cabin'] = full['Cabin'].map(cabin_category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Good practice to check the results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Name'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Name'] = full.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Name'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wohh that's lot's of title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Name'].value_counts(normalize = True) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Whoops! Apart from Mr, Miss, Mrs, and Master, the rest have percentages close to zero...\n\n### So, let's bundle them!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full.rename(columns={'Name' : 'Title'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Title'] = full['Title'].replace(['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Countess', \n                                       'Capt', 'Dona', 'Jonkheer', 'Lady', 'Sir', 'Mme', 'Don'], 'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full['Title'].value_counts(normalize = True) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Better! let's convert to numeric","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_category = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Other':5}\nfull['Title'] = full['Title'].map(title_category)\nfull['Title'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hmmm... but we know from part 2 that Sibsp is the number of siblings / spouses aboard the Titanic, and Parch is the number of parents / children aboard the Titanic... So, what is another straightforward feature to engineer?\n\n### Yes, it is the size of each family aboard!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full['familySize'] = full['SibSp'] + full['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop redundant features\nfull = full.drop(['SibSp', 'Parch', 'Ticket'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recover test dataset\ntest = full[full['Survived'].isna()].drop(['Survived'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recover train dataset\ntrain = full[full['Survived'].notna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Survived'] = train['Survived'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dateset is completely ready now!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived', 'PassengerId'], axis=1), train['Survived'], test_size = 0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nLogisticRegression = LogisticRegression(max_iter=10000)\nLogisticRegression.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = LogisticRegression.predict(X_test)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = (87+54) / (87+54+13+25) * 100\nacc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Magic Weapon #2: Cross-Validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" One of the most popular and efficient CV variants is **k-Fold Cross-Validation**, which we will choose to set our strong local validation scheme below. In a nutshell, k is the number of folds, mentioned above!\n\n Nice, now let's apply this key technique ourselves! We will use the basic version of k-Fold with **5 folds** from our friend, Scikit-learn!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncross_val_score(LogisticRegression, X_test, y_test, cv = kf).mean() * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Didn't Work","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Magic Weapon #3: Hyperparameter Tuning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" Secondly, I would like to introduce one of the most popular algorithms for classification (but also regression, etc), **Random Forest!** In a nutshell, Random Forest is an ensembling learning algorithm which combines **decision trees** in order to increase performance and avoid overfitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRandomForest = RandomForestClassifier(random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we set the hyperparameter grid of values with 4 lists of values:\n\n- **'criterion'** : A function which measures the quality of a split.\n- **'n_estimators'** : The number of trees of our random forest.\n- **'max_features'** : The number of features to choose when looking for the best way of splitting.\n- **'max_depth'** : the maximum depth of a decision tree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set our parameter grid\nparam_grid = { \n    'criterion' : ['gini', 'entropy'],\n    'n_estimators': [100, 300, 500],\n    'max_features': ['auto', 'log2'],\n    'max_depth' : [3, 5, 7]    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nrandomForest_CV = GridSearchCV(estimator = RandomForest, param_grid = param_grid, cv = 5)\nrandomForest_CV.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's print our optimal hyperparameters set!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"randomForest_CV.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"randomForestFinalModel = RandomForestClassifier(random_state = 2, criterion = 'gini', max_depth = 7, max_features = 'auto', n_estimators = 300)\n\nrandomForestFinalModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = randomForestFinalModel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, predictions) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's submit our solutions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Survived'] = randomForestFinalModel.predict(test.drop(['PassengerId'], axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['PassengerId', 'Survived']].to_csv('MySubmission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plz Upvote!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}