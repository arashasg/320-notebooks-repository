{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Lego Minifigure Classification - Transfer Learning using MobileNetV2\n\n![Lego](https://i.pinimg.com/originals/35/b7/0e/35b70e342fc3ad6e4d78f46febc05ebb.jpg)\n\n"},{"metadata":{},"cell_type":"markdown","source":"## We'll be going through the following steps from loading and preparing our data to training our model and finally validating our results.\n\n1. Importing Libraries\n\n2. Loading Dataset - Exploratory Data Analysis\n\n3. Data Preprocessing\n\n4. Loading Base Model for Transfer Learning \n\n5. Compiling Model\n\n6. Training Model\n\n7. Visualizing Model Accuracy and Loss\n\n8. Validation"},{"metadata":{},"cell_type":"markdown","source":"## 1. Importing Libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dropout, Dense\nfrom tensorflow.keras.applications import MobileNetV2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying directory files\nos.listdir('/kaggle/input/lego-minifigures-classification/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Initializing variable with path to dataset\ndataPath = '../input/lego-minifigures-classification/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing images using OpenCV and Matplotlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading image -> Resizing to (512x512) -> Converting to RGB -> Normalizing pixel values\n\nimage = cv2.imread('../input/lego-minifigures-classification/harry-potter/0002/009.jpg')\nimage = cv2.resize(image, (512,512))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Reading index.csv dataframe\nindex_df = pd.read_csv(dataPath + 'index.csv')\nindex_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading metadata.csv dataframe\nmeta_df = pd.read_csv(dataPath + 'metadata.csv')\nmeta_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merging index and metadata on class_id feature\ndata_df = pd.merge(index_df, meta_df[['class_id', 'minifigure_name']], on='class_id')\ndata_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying overall information\ndata_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking for missing data in dataframe\nprint(\"Missing Data:\",data_df.isnull().any().any())\ndata_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keeping count of number of each minifigure\nlabels = data_df['minifigure_name'].unique()\ncount = data_df['minifigure_name'].value_counts()\n\ncount","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing quantity of each minifugure in dataset\nimport seaborn as sns\n\nplt.figure(figsize=(12,10))\nsns.barplot(x=labels, y=count,palette=\"rocket\")\n\nplt.xticks(rotation= 90)\nplt.xlabel('Labels')\nplt.ylabel('Count')\nplt.title('Dataset Analysis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting and creating a training and validation dataframe \ntraining = data_df[data_df[\"train-valid\"] == 'train']\nvalidation = data_df[data_df[\"train-valid\"] == 'valid']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Viewing our prepared dataframes for training and validation\ntraining, validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating total number of classes\nCLASSES = len(data_df['class_id'].unique())\nCLASSES","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**We'll be preparing our image data for input to the Neural Network model.**\n\n* Creating numpy arrays for Train and Valid Data - Labels\n* Reading each image from training and validation dataframes using the 'path' feature\n* Converting image format to RGB from BGR\n* Resizing image to (512 x 512) \n* Normalizing pixel values between [0, 1] for each image\n* Appending data and labels to train and valid numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Data Preprocessing\n\ntrainData = np.zeros((training.shape[0], 512, 512, 3))\n\nfor i in range(training.shape[0]):\n    \n    image = cv2.imread('../input/lego-minifigures-classification/' + training[\"path\"].values[i])\n    \n    #Converting BGR to RGB \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    #Resizing image to (512 x 512)\n    image = cv2.resize(image, (512,512))\n    \n    #Normalizing pixel values to [0,1]\n    trainData[i] = image / 255.0\n\ntrainLabel = np.array(training[\"class_id\"])-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation Data Preprocessing\n\nvalidData = np.zeros((validation.shape[0], 512, 512, 3))\n\nfor i in range(validation.shape[0]):\n    \n    image = cv2.imread('../input/lego-minifigures-classification/' + validation[\"path\"].values[i])\n    \n    #Converting BGR to RGB \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    #Resizing image to (512 x 512)\n    image = cv2.resize(image, (512,512))\n    \n    #Normalizing pixel values to [0,1]\n    validData[i] = image / 255.0\n\nvalidLabel = np.array(validation[\"class_id\"])-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Viewing our prepared numpy arrays of data and labels\ntrainData, trainLabel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Loading Base Model for Transfer Learning"},{"metadata":{},"cell_type":"markdown","source":"* We will be taking advantage of Transfer Learning provided under the [tensorflow.keras.applications library](https://keras.io/guides/transfer_learning)\n* Using pretrained model weights of [MobileNetV2](https://keras.io/api/applications/mobilenet)\n* Loading MobileNetV2 as 'base_model'\n* Defining last two layers of MobileNetV2 as our trainable layers\n* Adding Droupout Layer of (0.5) - 50% neurons are dropped to prevent overfitting on data\n* Adding Dense Layer with number of CLASSES with a 'softmax' function\n* Creating Model with base model as inputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading Base Model\nbase_model = MobileNetV2()\n\n#Adding Dropout layer\nx = Dropout(0.5)(base_model.layers[-2].output)\n\n#Adding Dense layer\noutputs = Dense(CLASSES, activation='softmax')(x)\n\n#Creating model\nmodel = Model(base_model.inputs, outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Displaying model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Compiling Model using Adam Optimizer\n\n* Learning Rate - 0.0001\n* Loss Function - Sparse Categorical Crossentropy\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=Adam(lr=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Training Model - 30 Epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training model - 30 epochs\nhist = model.fit(\n    trainData, trainLabel,\n    epochs=40,\n    validation_data=(validData, validLabel),\n    shuffle=True,\n    batch_size=4\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Visualizing Model Performance\n\n* Plot 1 - Visualizing based on Model Loss \n* Plot 2 - Visualizing based on Model Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nplt.plot(hist.history['loss'], label='train loss')\nplt.plot(hist.history['val_loss'], label='valid loss')\nplt.grid()\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(hist.history['accuracy'], label='train acc')\nplt.plot(hist.history['val_accuracy'], label='valid acc')\nplt.grid()\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Validation\n\n* Loading test image from dataset\n* Preprocessing data - Resizing, Converting Format and Normalizing for input to trained model\n* Displaying test image "},{"metadata":{"trusted":true},"cell_type":"code","source":"testImage = cv2.imread('../input/lego-minifigures-classification/marvel/0001/001.jpg')\ntestImage = cv2.resize(testImage, (512,512))\ntestImage = cv2.cvtColor(testImage, cv2.COLOR_BGR2RGB) / 255.0\n\nplt.imshow(testImage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Reshaping and converting image data to numpy array\n* Prediciting on data \n* Displaying class name and minifigure name based on prediciton"},{"metadata":{"trusted":true},"cell_type":"code","source":"testImage = np.reshape(testImage, (1, 512, 512, 3))\n\npredictedClass = model.predict(testImage).argmax()\npredictedClass = predictedClass + 1\n\nfigureName = meta_df['minifigure_name'][meta_df['class_id'] == predictedClass].iloc[0]\n\nprint(figureName)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}