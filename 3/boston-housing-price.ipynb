{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# **Explain your model predictions with LIME**\n\n\n\nHello friends,\n\n\nIn a previous kernel. I have discussed [Shap library in Python](https://www.kaggle.com/prashant111/explain-model-predictions-with-shap), which is used for model interpretability. In this kernel, I will discuss LIME Values, which are also used for the same purpose.\n\nSo, let's get started."},{"metadata":{},"cell_type":"markdown","source":"**As always, I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES</b></font> would be highly appreciated**.\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n# **Table of Contents**\n\n- 1\t[Introduction to LIME](#1)\n- 2\t[Intuition behind LIME](#2)\n- 3\t[Python implementation of model development](#3)\n- 4\t[Interpret model predictions with LIME](#4)\n    - 4.1 [Import LIME package](#4.1)\n    - 4.2 [Create the explainer](#4.2)\n    - 4.3 [Use the explainer to explain predictions](#4.3)\n- 5 [References](#5)"},{"metadata":{},"cell_type":"markdown","source":"# **1. Introduction to LIME** <a class=\"anchor\" id=\"1\"></a>\n\n[Table of Contents](#0.1)\n\n\n- [LIME](https://christophm.github.io/interpretable-ml-book/lime.html) stands for **Local Interpretable Model-agnostic Explanations**. LIME focuses on training local surrogate models to explain individual predictions. Local surrogate models are interpretable models that are used to explain individual predictions of black box machine learning models. Surrogate models are trained to approximate the predictions of the underlying black box model. Instead of training a global surrogate model, LIME focuses on training local surrogate models.\n\n\n- LIME is model-agnostic, meaning that it can be applied to any machine learning model. The technique attempts to understand the model by perturbing the input of data samples and understanding how the predictions change."},{"metadata":{},"cell_type":"markdown","source":" ![LIME](https://miro.medium.com/max/1165/1*k-rxjnvUDTwk8Jfg6IYBkQ.png)"},{"metadata":{},"cell_type":"markdown","source":"- Model-specific approaches aim to understand the black model machine learning model by analysing the internal components and how they interact. LIME provides local model interpretability. LIME modifies a single data sample by tweaking the feature values and observes the resulting impact on the output. The most common question is probably: why was this prediction made or which variables caused the prediction."},{"metadata":{},"cell_type":"markdown","source":"# **2. Intuition behind LIME** <a class=\"anchor\" id=\"2\"></a>\n\n[Table of Contents](#0.1)\n\n\n- The intuition behind LIME is very simple. First, forget the training data and imagine we have only the black box model where we supply the input data. The black box model generate the predictions for the model. We can enquire the box as many times as we like. Our objective is to understand why the machine learning model made a certain prediction. \n\n- Now, [LIME](https://christophm.github.io/interpretable-ml-book/lime.html) comes into play. LIME tests what happens to the predictions when we provide variations in the data which is being fed into the machine learning model. \n\n- [LIME](https://christophm.github.io/interpretable-ml-book/lime.html) generates a new dataset consisting of permuted samples and the corresponding predictions of the black box model. On this new dataset LIME then trains an [interpretable model](https://christophm.github.io/interpretable-ml-book/simple.html#simple). It is weighted by the proximity of the sampled instances to the instance of interest. The learned model should be a good approximation of the machine learning model predictions locally, but it does not have to be a good global approximation. This kind of accuracy is also called local fidelity."},{"metadata":{},"cell_type":"markdown","source":"- Mathematically, local surrogate models with interpretability constraint can be expressed as follows:\n\n        `explanation(x)=arg ming∈G L(f,g,πx)+Ω(g)`"},{"metadata":{},"cell_type":"markdown","source":"- The explanation model for instance x is the model g (e.g. linear regression model) that minimizes loss function L (e.g. mean squared error). It measures how close the explanation is to the prediction of the original model f (e.g. an xgboost model), while the model complexity Ω(g) is kept low (e.g. prefer fewer features). G is the family of possible explanations. \n\n- In practice, LIME only optimizes the loss part. The user has to determine the complexity, e.g. by selecting the maximum number of features that the linear regression model may use.\n\n- So, the recipe for training local surrogate models is as follows:\n\n  - 1 Select your instance of interest for which you want to have an explanation of its black box prediction.\n  - 2 Perturb your dataset and get the black box predictions for these new points.\n  - 3 Weight the new samples according to their proximity to the instance of interest.\n  - 4 Train a weighted, interpretable model on the dataset with the variations.\n  - 5 Explain the prediction by interpreting the local model."},{"metadata":{},"cell_type":"markdown","source":"# **3. Python Implementation of model development** <a class=\"anchor\" id=\"3\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## **3.1 Load Preliminaries** <a class=\"anchor\" id=\"3.1\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.2 Read Data** <a class=\"anchor\" id=\"3.2\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read and preview data\ndf = pd.read_csv('/kaggle/input/boston-housing-dataset/HousingData.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.3 View Summary of data** <a class=\"anchor\" id=\"3.3\"></a>\n\n[Table of Contents](#0.1)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.4 Missing values treatment** <a class=\"anchor\" id=\"3.4\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see that there are quite a lot of missing values in the dataset. For convinience, I will fill them by the mean of respective columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.fillna(df.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Again check for missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now, we can see that there are no missing values in the data."},{"metadata":{},"cell_type":"markdown","source":"## **3.5 Feature Vector and Target Variable** <a class=\"anchor\" id=\"3.5\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Declare feature vector and target variable\nX = df[['LSTAT','RM','NOX','PTRATIO','DIS','AGE']]\ny = df['MEDV']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here, I have seelcted the following 6 variables as feature vectors for convinience.\n\n  - 1 `LSTAT` - lower status of the population\n  - 2 `RM` - average number of rooms per housing\n  - 3 `NOX` - nitric oxides concentration (parts per 10 million)\n  - 4 `PTRATIO` - pupil-teacher ratio by town\n  - 5 `DIS` - weighted distances to five Boston employment centres\n  - 6 `AGE` - proportion of owner-occupied units built prior to 1940\n  \n- The target variable is `MEDV` which stands for **Median value of owner-occupied homes**.\n\n- The dataset description can be found at -\n\n    https://www.kaggle.com/kyasar/boston-housing"},{"metadata":{},"cell_type":"markdown","source":"## **3.6 Train-Test Split** <a class=\"anchor\" id=\"3.6\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into train and test data:\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.7 Build the Random Forest model** <a class=\"anchor\" id=\"3.7\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the model with Random Forest Regressor :\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.8 Generate Predictions** <a class=\"anchor\" id=\"3.8\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.9 Evaluate Performance** <a class=\"anchor\" id=\"3.9\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)**(0.5)\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Interpret model predictions with LIME** <a class=\"anchor\" id=\"4\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"## **4.1 Import LIME package** <a class=\"anchor\" id=\"4.1\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lime\nimport lime.lime_tabular","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4.2 Create the Explainer** <a class=\"anchor\" id=\"4.2\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LIME has one explainer for all the models\nexplainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values.tolist(),\n                                                  class_names=['MEDV'], verbose=True, mode='regression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4.3 Use the explainer to explain predictions** <a class=\"anchor\" id=\"4.3\"></a>\n\n[Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"- Here, I will choose 5 instances and use them to explain the predictions."},{"metadata":{},"cell_type":"markdown","source":"## **Select 5th instance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose the 5th instance and use it to predict the results\nj = 5\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the predictions\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Interpretation**\n\n- The predicted value of the house price is 21.48.\n- The variables `LSTAT` and `NOX` have positive influence while `RM`,`DIS`,`AGE` and`PTRATIO` have negative influence on predicted house prices.\n- All the values are in thousands of dollars."},{"metadata":{},"cell_type":"markdown","source":"## **Select 10th instance**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose the 10th instance and use it to predict the results\nj = 10\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the predictions\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Interpretation**\n\n- The predicted value of the house price is 9.78.\n- All the variables have negative influence on the predicted house prices.\n- All the values are in thousands of dollars."},{"metadata":{},"cell_type":"markdown","source":"## **Select 15th instance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose the 15th instance and use it to predict the results\nj = 15\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the predictions\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Interpretation**\n\n- The predicted value of the house price is 33.48.\n- All the variables except `DIS` have positive influence on the predicted house prices.\n- All the values are in thousnads of dollars."},{"metadata":{},"cell_type":"markdown","source":"## **Select 20th instance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose the 20th instance and use it to predict the results\nj = 20\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the predictions\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Interpretation**\n\n- The predicted value of the house price is 23.75.\n- The variables `LSTAT` and`NOX` have positive influence while `RM`, `AGE`,`PTRATIO` and `DIS` have negative influence on predicted house prices.\n- All the values are in thousands of dollars."},{"metadata":{},"cell_type":"markdown","source":"## **Select 25th instance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose the 25th instance and use it to predict the results\nj = 25\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the predictions\nexp.show_in_notebook(show_table=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Interpretation**\n\n- The predicted value of the house price is 16.67.\n- All the variables have negative influence on predicted house prices.\n- All the values are in thousands of dollars."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"# **5. References** <a class=\"anchor\" id=\"5\"></a>\n\n[Table of Contents](#0.1)\n\n\nThe work done in this kernel is based on the following websites -\n\n- 1 https://christophm.github.io/interpretable-ml-book/\n- 2 https://christophm.github.io/interpretable-ml-book/lime.html\n- 3 https://blog.dominodatalab.com/shap-lime-python-libraries-part-2-using-shap-lime/\n- 4 https://www.analyticsvidhya.com/blog/2017/06/building-trust-in-machine-learning-models/\n- 5 https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b\n- 6 https://marcotcr.github.io/lime/tutorials/Using%2Blime%2Bfor%2Bregression.html"},{"metadata":{},"cell_type":"markdown","source":"[Go to Top](#0)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}