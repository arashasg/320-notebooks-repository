{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Load necessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import multiprocessing as mp\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport tqdm\nimport multiprocessing as mp\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = \"../input/test_preprocessed/\"\nif not os.path.exists(directory):\n    os.makedirs(directory)\n    \ndf = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nDATA_ROOT = '../input/aptos2019-blindness-detection/test_images/'\nOUTPUT_DIR = directory\nSIZE = 224","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    # Taken from https://www.kaggle.com/ratthachat/aptos-updatedv14-preprocessing-ben-s-cropping\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef circle_crop(img):  \n    # Taken from  https://www.kaggle.com/taindow/pre-processing-train-and-test-images\n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = crop_image_from_gray(img)    \n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    \n    return img \n\ndef preprocess_image(df, run_root=DATA_ROOT, out_root=OUTPUT_DIR, size=SIZE):\n    df = df.reset_index()\n    for i in tqdm.tqdm(range(df.shape[0])):\n        item = df.iloc[i]\n        path = run_root+item.id_code+'.png'\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = circle_crop(img)\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(OUTPUT_DIR + item.id_code + '.png',img) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess image parallelly"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_cpu = mp.cpu_count()\npool = mp.Pool(n_cpu)\nn_cnt = df.shape[0] // n_cpu\ndfs = [df.iloc[n_cnt*i:n_cnt*(i+1)] for i in range(n_cpu)]\ndfs[-1] = df.iloc[n_cnt*(n_cpu-1):] \nres = pool.map(preprocess_image, [x_df for x_df in dfs])\npool.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compare raw and processed images"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2)\nimg_raw = cv2.imread(DATA_ROOT + df.iloc[0].id_code + '.png')\nimg_raw = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n\nimg = cv2.imread(OUTPUT_DIR + df.iloc[0].id_code + '.png', cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\naxes[0].imshow(img_raw)\naxes[1].imshow(img)\nprint(img_raw.shape, img.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove the directory at the end"},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists(directory):\n    !rm -r '../input/test_preprocessed'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}