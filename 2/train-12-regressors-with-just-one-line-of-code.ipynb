{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Demo Notebook for quick_regression utility script"},{"metadata":{},"cell_type":"markdown","source":"### <font color=\"darkred\">What if we could score 12+ common regression classifiers on our data with just one line of code? \n\nFor the Ames Housing Price competition I experimented with a scikit Pipeline to automically clean and prepare the data, handle numerical and categorical values and crossvalidate on the most common classifiers being used by fellow Kagglers. See the complete notebook here:\n\nhttps://www.kaggle.com/chmaxx/sklearn-pipeline-playground-for-10-classifiers\n\nThis experimental playground I extended to this small utility script that can be used on any training data for a regression problem:\n\nhttps://www.kaggle.com/chmaxx/quick-regression"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nfrom tabulate import tabulate\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\n\n# we import the three main functions from the utility script for scoring, training and prediction\nfrom quick_regression import score_models\nfrom quick_regression import train_models\nfrom quick_regression import predict_from_models\n\nBASE = \"/kaggle/input\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try the script on a first regression problem: Predicting miles per gallon from car data. The data is [taken from seaborn demo data here](https://github.com/mwaskom/seaborn-data)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(f\"{BASE}/sample-data/mpg.csv\")\n# score_models() just expects your training data as a Pandas dataframe and the column name of the target variable\n# the function prints out scoring values (\"r2\" by default) and processing times per classifier\nscores_mpg = score_models(df, \"mpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In just a couple of seconds we get a first impression how several algorithms perform!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the utility script returns a dataframe with a sorted list of scores of 14 classifiers\nprint(tabulate(scores_mpg, showindex=False, floatfmt=\".3f\", headers=\"keys\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can tune the scoring by providing several parameters. These are the defaults. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_mpg = score_models(df=df, \n                          target_name=\"mpg\", \n                          sample_size=None, \n                          impute_strategy=\"mean\", \n                          scoring_metric=\"r2\", \n                          log_x=False,\n                          log_y=False, \n                          verbose=True,\n                         )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we have a larger dataset we can e.g. score on a subsample of our data to speed up execution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# the diamonds data set has more than 50k samples which would take a while to crossvalidate on 14 classifiers\n# we therefore reduce to 1000 samples\ndf = pd.read_csv(f\"{BASE}/sample-data/diamonds.csv\")\nscores_diamonds = score_models(df, \"price\", sample_size=1000, verbose=False)\nprint()\nprint(tabulate(scores_diamonds, showindex=False, floatfmt=\".3f\", headers=\"keys\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can log transform the target variable to see if it improves scoring. We can also log transform all the numerical predictive variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(f\"{BASE}/house-prices-advanced-regression-techniques/train.csv\")\nscores_ames = score_models(df, \"SalePrice\", verbose=False)\nprint(tabulate(scores_ames, showindex=False, floatfmt=\".3f\", headers=\"keys\"))\nprint()\n\n# now trying with log transformed target variable y\nscores_ames = score_models(df, \"SalePrice\", log_y=True, verbose=False)\nprint(tabulate(scores_ames, showindex=False, floatfmt=\".3f\", headers=\"keys\"))\nprint()\n\n# now trying with log transformed predictive variables\nscores_ames = score_models(df, \"SalePrice\", log_x=True, log_y=True, verbose=False)\nprint(tabulate(scores_ames, showindex=False, floatfmt=\".3f\", headers=\"keys\"))\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now on to training and prediction... With just one more line we train all classifiers on the full training set. The function returns the fitted scikit Pipelines.\n\nWe can use these in the next step to predict from the test data. Just be aware: The first column are the predictions from the DummyRegressor. This will very likely spoil your result... ðŸ˜‰"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipelines = train_models(df, \"SalePrice\", log_y=True)\n\ndf_test = pd.read_csv(f\"{BASE}/house-prices-advanced-regression-techniques/test.csv\")\npredictions = predict_from_models(df_test, pipelines)\npredictions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try some more Kaggle datasets out of the box and see what happens."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(f\"{BASE}/tmdb-box-office-prediction/train.csv\")\nbaseline_tmdb = score_models(df, \"revenue\", 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Behind the scenes\nAt the core of the util script I used scikit-learn's pipeline class. This allows to chain arbitrary transformers with a final estimator. Let's look at a simple example. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(f\"{BASE}/house-prices-advanced-regression-techniques/train.csv\")\nX = df.select_dtypes(\"number\").drop(\"SalePrice\", axis=1)\ny = df.SalePrice\n\n# using the convenience function make_pipeline() to build a whole data pipeline in just one line of code\npipe = make_pipeline(SimpleImputer(), RobustScaler(), LinearRegression())\nprint(f\"The R2 score is: {cross_val_score(pipe, X, y).mean():.4f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The same we can setup with two pipeline branches for numerical and categorical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = df.drop(\"SalePrice\", axis=1).select_dtypes(\"number\").columns\ncat_cols = df.select_dtypes(\"object\").columns\n\n# we instantiate a first Pipeline, that processes our numerical values\nnumeric_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer()),\n        ('scaler', RobustScaler())])\n\n# the same we do for categorical data\ncategorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n    \n# a ColumnTransformer combines the two created pipelines\n# each tranformer gets the proper features according to Â«num_colsÂ» and Â«cat_colsÂ»\npreprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, num_cols),\n            ('cat', categorical_transformer, cat_cols)])\n\npipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LinearRegression())])\n\nX = df.drop(\"SalePrice\", axis=1)\ny = df.SalePrice\nprint(f\"The R2 score is: {cross_val_score(pipe, X, y).mean():.4f}\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=\"darkred\">**The script simply abstracts all this away and in addition takes care of instantiating the classifiers, crossvalidation, training and prediction.**"},{"metadata":{},"cell_type":"markdown","source":"### References\n\n[Alexis' Kaggle Tutorial](https://www.kaggle.com/alexisbcook/pipelines)<br>\n[Dan Becker's Pipeline Tutorial](https://www.kaggle.com/dansbecker/pipelines)<br>\n[Using the Column Transformer](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}