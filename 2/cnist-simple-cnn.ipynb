{"cells":[{"metadata":{},"cell_type":"markdown","source":"Using some techniques from the following sources:\n* https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n* https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n* https://www.kaggle.com/poonaml/deep-neural-network-keras-way"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Suppress multiple warnings\nimport warnings\nwarnings.filterwarnings(action='once')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries and modules\nimport numpy as np\nimport pandas as pd\nimport os\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Files in directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data & split into test and train"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import train\nTrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\nprint(Train.shape)\n\n# Import test\nX_test= pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nprint(X_test.shape)\n\n# Quick look at the data\nTrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The extra column in Train is for the label. Otherwise both the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train into X & Y\ny_train = Train.label\nX_train = Train.drop('label',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tensorflow requires inputs to not be in Pandas dataframe format. Numpy arrays are okay."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert all into numpy arrays\ny_train = y_train.values\nX_train = X_train.values\nX_test = X_test.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll split the training data into t_train (80%) and t_test (20%) sets. The t_test is sometimes referred to as the 'validation' set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train data into t_train and t_test sets\nfrom sklearn.model_selection import train_test_split\nXt_train, Xt_test, yt_train, yt_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Each image is currently stored as a (784x1) array. See below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Return shape of 1st item in list\nXt_train[0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know that the images are (28x28) images. If we wanted to visualise an image we would have to reshape it from (784x1) to (29x28). Note they are greyscale."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualise data\n\nimport matplotlib.pyplot as plt \ndata_no = 6\nplt.imshow(Xt_train[data_no].reshape(28, 28))\nplt.title('Label: ' + str(yt_train[data_no]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Preprocess input data\n\n# Good practice (and better performance) to ensure the values are less than 1. To do this we'll calculate the max value and scale all numbers by that.\nscaling_value = max(Xt_train.max().max(),Xt_test.max().max(),X_test.max().max())\nXt_train = Xt_train/ scaling_value\nXt_test = Xt_test/ scaling_value\nX_test = X_test/ scaling_value\n\n# Convert inputs into right form for model shape (n, width, height) to (n, depth, width, height), where n is number of records.\nXt_train = Xt_train.reshape(Xt_train.shape[0], 28, 28, 1)\nXt_test = Xt_test.reshape(Xt_test.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n# Ensure inputs are correct type\nXt_train = Xt_train.astype('float32')\nXt_test = Xt_test.astype('float32')\nX_test = X_test.astype('float32')\n\n# Preprocess class labels (we require these to be one-hot encoded i.e. for 3 [0,0,1,0,0,0,0,0,0])\nfrom keras.utils import np_utils\nyt_train = np_utils.to_categorical(yt_train, 10)\nyt_test = np_utils.to_categorical(yt_test, 10)\n\n# Sense check some parameters\nprint('Scaling value: ' + str(scaling_value))\nprint(Xt_train.shape)\nprint(yt_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model architectural setup "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\n\n# Define model architecture\nmodel = Sequential() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\n# Add layers\n\n# The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image.\n# A 3x3 kernal (or filter) is passed across the image\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\nprint(model.output_shape)\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\nprint(model.output_shape)\n\n# MaxPooling2D is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter\n# across the previous layer and taking the max of the 4 values in the 2x2 filter\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nprint(model.output_shape)\n\n# Dropout is a method for regularizing our model in order to prevent overfitting.\nmodel.add(Dropout(0.25))\nprint(model.output_shape)\n\n# Deep network requires to be converted into a 1-D array\nmodel.add(Flatten())\nprint(model.output_shape)\n\n# Add a couple of fully connected dense layers\nmodel.add(Dense(128, activation='relu'))\nprint(model.output_shape)\n# Last layer is out output so a 'softmax' outputs a probability distribution between 0 and 1\nmodel.add(Dense(10, activation='softmax'))\nprint(model.output_shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit model on 70% of training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model on training data\nstart = datetime.datetime.now()\nmodel.fit(Xt_train, yt_train, batch_size=32, nb_epoch=10, verbose=1)\nprint('Time taken: ' + str((datetime.datetime.now()-start).total_seconds()) + ' seconds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate model on unseen (30%) training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model on test data\nscore = model.evaluate(Xt_test, yt_test, verbose=0)\nprint(model.metrics_names[0] + \": \" + str(score[0]))\nprint(model.metrics_names[1] + \": \" + str(score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit model on ALL training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model on ALL training data\nX_train = np.concatenate([Xt_train,Xt_test],axis=0)\ny_train = np.concatenate([yt_train,yt_test],axis=0)\nstart = datetime.datetime.now()\nmodel.fit(X_train, y_train, batch_size=32, nb_epoch=10, verbose=1)\nprint('Time taken: ' + str((datetime.datetime.now()-start).total_seconds()) + ' seconds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict results on test set\nresults = model.predict(X_test)\n\n# Select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\n# Put into dataframe and add Id column\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\n# Check submission looks correct\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check one result\ntest_no = 0\nplt.imshow(X_test[test_no].reshape(28, 28))\nplt.title('Predicted Label: ' + str(submission.Label[test_no]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output to csv for submission\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}